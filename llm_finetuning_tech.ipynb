{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14cfb25cc4d145519a89fdb812afd4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8703d8b614434a28b727949780818bbf",
              "IPY_MODEL_4277c6ba2d8d456589ea0c5fc399822f",
              "IPY_MODEL_79b7657130474e93ab6e891744c333ee"
            ],
            "layout": "IPY_MODEL_01a664f04c9d48ef9e9935674f772425"
          }
        },
        "8703d8b614434a28b727949780818bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8504eac8129d467c922e23f3464e8134",
            "placeholder": "​",
            "style": "IPY_MODEL_5c9c1e00c8564037bf37f55d635ea985",
            "value": "Map: 100%"
          }
        },
        "4277c6ba2d8d456589ea0c5fc399822f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a36f5f9541a84314ac8d67e18140d6d0",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2213a4967ca24263b9e62c4195726b84",
            "value": 6
          }
        },
        "79b7657130474e93ab6e891744c333ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90262b04923b422ba84abab6519f4c4d",
            "placeholder": "​",
            "style": "IPY_MODEL_ad471158c8624d58b22632ca88063a92",
            "value": " 6/6 [00:00&lt;00:00, 53.42 examples/s]"
          }
        },
        "01a664f04c9d48ef9e9935674f772425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8504eac8129d467c922e23f3464e8134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9c1e00c8564037bf37f55d635ea985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a36f5f9541a84314ac8d67e18140d6d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2213a4967ca24263b9e62c4195726b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90262b04923b422ba84abab6519f4c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad471158c8624d58b22632ca88063a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58d52e3db62e480db79e9a6d2d2fe1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b58f290691144106a90a6bbf01355635",
              "IPY_MODEL_5a736e08d6fb409db9d2019bc8296643",
              "IPY_MODEL_8a2e8a8f279b4a55b54f3e5e6bf2f7d8"
            ],
            "layout": "IPY_MODEL_85c37a6505004f76937752e3dcfc8ee3"
          }
        },
        "b58f290691144106a90a6bbf01355635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab3a4c7d6ca9458a98c248e83f2a463f",
            "placeholder": "​",
            "style": "IPY_MODEL_3540e1c5d6de4d568b045af9c9cc163d",
            "value": "Map: 100%"
          }
        },
        "5a736e08d6fb409db9d2019bc8296643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aaabc631e974e8794b4f71a26b61f80",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b44f855002b4d8793dd00bb105ba485",
            "value": 2
          }
        },
        "8a2e8a8f279b4a55b54f3e5e6bf2f7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2d46e7c876a49a18c4265bbcbace41b",
            "placeholder": "​",
            "style": "IPY_MODEL_fe6ec56035ef464bb8844c0dcba29df5",
            "value": " 2/2 [00:00&lt;00:00, 65.31 examples/s]"
          }
        },
        "85c37a6505004f76937752e3dcfc8ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3a4c7d6ca9458a98c248e83f2a463f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3540e1c5d6de4d568b045af9c9cc163d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8aaabc631e974e8794b4f71a26b61f80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b44f855002b4d8793dd00bb105ba485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2d46e7c876a49a18c4265bbcbace41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe6ec56035ef464bb8844c0dcba29df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lUWxp3g9zK_Z"
      },
      "outputs": [],
      "source": [
        "!pip install numpy transformers>=4.43 datasets>=2.19 accelerate>=0.33 peft>=0.12 bitsandbytes jinja2 trl>=0.9\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline_infer_tinyllama.py\n",
        "# ---\n",
        "# Minimal, stable baseline generation for TinyLlama-1.1B-Chat-v1.0\n",
        "# Uses the model's chat template + safer decoding settings\n",
        "# Works on CPU, Apple Silicon (MPS), or NVIDIA GPU.\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "MODEL_ID = os.environ.get(\"MODEL_ID\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "\n",
        "# Pick best available device\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE, TORCH_DTYPE = \"cuda\", torch.float16\n",
        "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
        "    DEVICE, TORCH_DTYPE = \"mps\", torch.float16\n",
        "else:\n",
        "    DEVICE, TORCH_DTYPE = \"cpu\", None\n",
        "\n",
        "def build_messages_api_doc(endpoint_block: str):\n",
        "    \"\"\"\n",
        "    Build a simple two-turn chat: system + user.\n",
        "    You can swap this builder for your own task later.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are a precise technical writer. Follow this API doc template strictly:\\n\"\n",
        "                \"Summary\\nEndpoint\\nParameters (markdown table)\\nResponses\\n\"\n",
        "                \"Do not invent extra turns. Keep it concise and consistent.\"\n",
        "            ),\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Write an API doc page.\\n{endpoint_block}\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "def generate_api_doc(endpoint_block: str, max_new_tokens: int = 320) -> str:\n",
        "    tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "    if tok.pad_token is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_ID,\n",
        "        torch_dtype=TORCH_DTYPE if TORCH_DTYPE is not None else None\n",
        "    ).to(DEVICE).eval()\n",
        "\n",
        "    # Use the model's chat template for stable formatting\n",
        "    messages = build_messages_api_doc(endpoint_block)\n",
        "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tok(prompt, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "\n",
        "    # Generate with tighter, de-looped settings\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.5,         # lower = more structured\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,  # discourages repeating tags/lines\n",
        "            pad_token_id=tok.eos_token_id,\n",
        "        )\n",
        "\n",
        "    # --- Clean extraction: only new tokens after the prompt (no echo) ---\n",
        "    generated_ids = out[0]\n",
        "    prompt_len = inputs[\"input_ids\"].shape[-1]\n",
        "    new_tokens = generated_ids[prompt_len:]\n",
        "    text = tok.decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "    # Light post-trim: stop if the model starts a new bracketed section\n",
        "    # (keeps first coherent block; optional but helps with small models)\n",
        "    cut_markers = [\"\\n[\", \"\\n<System\", \"\\nUser:\", \"\\nAssistant:\"]\n",
        "    for m in cut_markers:\n",
        "        if m in text:\n",
        "            text = text.split(m, 1)[0]\n",
        "    return text.strip()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example baseline prompt (same one you used earlier)\n",
        "    endpoint = (\n",
        "        \"Endpoint: POST /v1/refunds; Auth: Bearer token; \"\n",
        "        \"Params: payment_id (string, required), amount (integer, optional); \"\n",
        "        \"Response: 201 {refund}, 400, 401\"\n",
        "    )\n",
        "    print(\"\\n=== BASELINE (TinyLlama chat template) ===\\n\")\n",
        "    print(generate_api_doc(endpoint))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBeM3IS5zYyS",
        "outputId": "0e829bcc-9c1c-4b34-8aa2-57640dcabc84"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== BASELINE (TinyLlama chat template) ===\n",
            "\n",
            "[API Doc Page]\n",
            "\n",
            "Name: Refund API\n",
            "\n",
            "Description: This API allows you to create, retrieve, update, and delete refunds for your products.\n",
            "\n",
            "Endpoint: /v1/refunds\n",
            "\n",
            "Method: POST\n",
            "\n",
            "Auth: Bearer token\n",
            "\n",
            "Required Params:\n",
            "- payment_id (string, required): The unique identifier of the payment method used to make the purchase.\n",
            "- amount (integer, optional): The total amount due for the refund. If omitted, the default value is 0.\n",
            "\n",
            "Optional Params:\n",
            "- currency (string, optional): The currency code used to convert the amount to USD. Defaults to \"USD\".\n",
            "- description (string, optional): A human-readable description of the reason for the refund.\n",
            "\n",
            "Response:\n",
            "- 201: Created - Indicates that the refund was successfully created.\n",
            "- 400: Bad Request - If any of the parameters provided in the request are invalid.\n",
            "- 401: Unauthorized - If the user does not have sufficient permissions to access the requested resource.\n",
            "\n",
            "Example Request:\n",
            "```\n",
            "curl -X POST \\\n",
            "  https://api.example.com/v1/refunds \\\n",
            "  -H 'Authorization: Bearer <your_access_token>' \\\n",
            "  -H 'Content-Type: application/json' \\\n",
            "  -d '{\n",
            "    \"payment_id\": \"5678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_templates.py\n",
        "\n",
        "SYS_TECH = (\n",
        "    \"You are a precise technical writer. Follow this API doc template strictly:\\n\"\n",
        "    \"Summary\\nEndpoint\\nParameters (markdown table)\\nResponses\\n\"\n",
        "    \"Do not invent extra turns. Keep it concise and consistent.\"\n",
        ")\n",
        "\n",
        "SYS_LEGAL = \"You are a pragmatic legal drafter. Be clear, concise, and neutral. Prefer short clauses.\"\n",
        "SYS_MARKETING = \"You are a sharp marketing copywriter. Be concise, on-brand, and punchy. Prefer strong verbs and clear CTAs.\"\n",
        "\n",
        "def system_for_domain(domain: str) -> str:\n",
        "    return {\n",
        "        \"tech\": SYS_TECH,\n",
        "        \"legal\": SYS_LEGAL,\n",
        "        \"marketing\": SYS_MARKETING,\n",
        "    }.get(domain, \"You are helpful and concise.\")\n",
        "\n",
        "def build_messages(domain: str, instruction: str, input_text: str = \"\"):\n",
        "    \"\"\"Return a standard system+user two-turn chat.\"\"\"\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_for_domain(domain)},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction.strip()}\\n{(input_text or '').strip()}\"},\n",
        "    ]\n",
        "\n",
        "def build_chat_text(tokenizer, domain: str, instruction: str, input_text: str = \"\") -> str:\n",
        "    \"\"\"Render the chat prompt to plain text using the model's chat template.\"\"\"\n",
        "    msgs = build_messages(domain, instruction, input_text)\n",
        "    return tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n"
      ],
      "metadata": {
        "id": "f_IXnGuz1xNr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_lora_tinyllama_tech.py\n",
        "import os, math\n",
        "from typing import List, Dict\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForCausalLM,\n",
        "    DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "\n",
        "MODEL_ID    = os.environ.get(\"MODEL_ID\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "OUTPUT_DIR  = os.environ.get(\"OUTPUT_DIR\", \"outputs/tinyllama-tech-lora\")\n",
        "SEED        = int(os.environ.get(\"SEED\", 42))\n",
        "MAX_LENGTH  = int(os.environ.get(\"MAX_LENGTH\", 512))\n",
        "EPOCHS      = float(os.environ.get(\"EPOCHS\", 1))\n",
        "BATCH_SIZE  = int(os.environ.get(\"BATCH_SIZE\", 1))\n",
        "GRAD_ACC    = int(os.environ.get(\"GRAD_ACC\", 4))\n",
        "LR          = float(os.environ.get(\"LR\", 2e-4))\n",
        "\n",
        "# device\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "# tiny TECH dataset (emphasizes strict 4-section template)\n",
        "TRAIN: List[Dict] = [\n",
        "    {\n",
        "        \"instruction\": \"Write an API doc page.\",\n",
        "        \"input\": \"Endpoint: POST /v1/invoices; Auth: Bearer token; Params: customer_id (string, required), line_items (array, required); Response: 201 {invoice_id}\",\n",
        "        \"output\": \"\"\"Summary\n",
        "Create an invoice for a given customer.\n",
        "\n",
        "Endpoint\n",
        "POST /v1/invoices\n",
        "Auth: Bearer <token>\n",
        "\n",
        "Parameters\n",
        "| Name        | Type   | Required | Description                  |\n",
        "|-------------|--------|----------|------------------------------|\n",
        "| customer_id | string | yes      | Customer identifier          |\n",
        "| line_items  | array  | yes      | Line items to be invoiced    |\n",
        "\n",
        "Responses\n",
        "- 201 Created: {\"invoice_id\": \"inv_123\"}\n",
        "- 400 Bad Request\n",
        "- 401 Unauthorized\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Write an API doc page.\",\n",
        "        \"input\": \"Endpoint: GET /v1/invoices/{id}; Auth: Bearer token; Params: id (string, path, required); Response: 200 {invoice}\",\n",
        "        \"output\": \"\"\"Summary\n",
        "Retrieve an invoice by ID.\n",
        "\n",
        "Endpoint\n",
        "GET /v1/invoices/{id}\n",
        "Auth: Bearer <token>\n",
        "\n",
        "Parameters\n",
        "| Name | Type   | Required | In   | Description     |\n",
        "|------|--------|----------|------|-----------------|\n",
        "| id   | string | yes      | path | Invoice ID      |\n",
        "\n",
        "Responses\n",
        "- 200 OK: {\"id\":\"inv_123\",\"status\":\"paid\",...}\n",
        "- 401 Unauthorized\n",
        "- 404 Not Found\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Write an API doc page.\",\n",
        "        \"input\": \"Endpoint: DELETE /v1/invoices/{id}; Auth: Bearer token; Params: id (string, path, required); Response: 204 No Content\",\n",
        "        \"output\": \"\"\"Summary\n",
        "Delete an invoice by ID.\n",
        "\n",
        "Endpoint\n",
        "DELETE /v1/invoices/{id}\n",
        "Auth: Bearer <token>\n",
        "\n",
        "Parameters\n",
        "| Name | Type   | Required | In   | Description     |\n",
        "|------|--------|----------|------|-----------------|\n",
        "| id   | string | yes      | path | Invoice ID      |\n",
        "\n",
        "Responses\n",
        "- 204 No Content\n",
        "- 401 Unauthorized\n",
        "- 404 Not Found\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Write an API doc page.\",\n",
        "        \"input\": \"Endpoint: POST /v1/customers; Auth: Bearer token; Params: email (string, required), name (string, optional); Response: 201 {customer}\",\n",
        "        \"output\": \"\"\"Summary\n",
        "Create a customer.\n",
        "\n",
        "Endpoint\n",
        "POST /v1/customers\n",
        "Auth: Bearer <token>\n",
        "\n",
        "Parameters\n",
        "| Name | Type   | Required | Description        |\n",
        "|------|--------|----------|--------------------|\n",
        "| email| string | yes      | Customer email     |\n",
        "| name | string | no       | Customer name      |\n",
        "\n",
        "Responses\n",
        "- 201 Created: {\"id\":\"cus_123\", ...}\n",
        "- 400 Bad Request\n",
        "- 401 Unauthorized\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Write an API doc page.\",\n",
        "        \"input\": \"Endpoint: PATCH /v1/customers/{id}; Auth: Bearer token; Params: id (string, path, required), name (string, optional); Response: 200 {customer}\",\n",
        "        \"output\": \"\"\"Summary\n",
        "Update a customer.\n",
        "\n",
        "Endpoint\n",
        "PATCH /v1/customers/{id}\n",
        "Auth: Bearer <token>\n",
        "\n",
        "Parameters\n",
        "| Name | Type   | Required | In   | Description    |\n",
        "|------|--------|----------|------|----------------|\n",
        "| id   | string | yes      | path | Customer ID    |\n",
        "| name | string | no       | body | Customer name  |\n",
        "\n",
        "Responses\n",
        "- 200 OK: {\"id\":\"cus_123\",\"name\":\"...\"}\n",
        "- 401 Unauthorized\n",
        "- 404 Not Found\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Write an API doc page.\",\n",
        "        \"input\": \"Endpoint: GET /v1/customers; Auth: Bearer token; Params: limit (integer, optional), cursor (string, optional); Response: 200 {customers[]}\",\n",
        "        \"output\": \"\"\"Summary\n",
        "List customers with pagination.\n",
        "\n",
        "Endpoint\n",
        "GET /v1/customers\n",
        "Auth: Bearer <token>\n",
        "\n",
        "Parameters\n",
        "| Name   | Type    | Required | Description                 |\n",
        "|--------|---------|----------|-----------------------------|\n",
        "| limit  | integer | no       | Max items to return         |\n",
        "| cursor | string  | no       | Pagination cursor           |\n",
        "\n",
        "Responses\n",
        "- 200 OK: [{\"id\":\"cus_...\"}...]\n",
        "- 401 Unauthorized\"\"\"\n",
        "    },\n",
        "]\n",
        "\n",
        "EVAL = TRAIN[:2]\n",
        "\n",
        "def row_to_text_chat(tok, ex: Dict) -> str:\n",
        "    # domain \"tech\" for this demo\n",
        "    return build_chat_text(tok, \"tech\", ex[\"instruction\"], ex.get(\"input\", \"\")) + ex[\"output\"]\n",
        "\n",
        "def main():\n",
        "    tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "    if tok.pad_token is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "    tok.padding_side = \"right\"\n",
        "\n",
        "    ds_train = Dataset.from_list(TRAIN)\n",
        "    ds_eval  = Dataset.from_list(EVAL)\n",
        "\n",
        "    cols = list(ds_train.features.keys())\n",
        "    tok_train = ds_train.map(lambda ex: tok(row_to_text_chat(tok, ex), truncation=True, max_length=MAX_LENGTH, padding=False),\n",
        "                             remove_columns=cols)\n",
        "    tok_eval  = ds_eval.map (lambda ex: tok(row_to_text_chat(tok, ex), truncation=True, max_length=MAX_LENGTH, padding=False),\n",
        "                             remove_columns=cols)\n",
        "\n",
        "    base = AutoModelForCausalLM.from_pretrained(MODEL_ID)\n",
        "    try:\n",
        "        base.gradient_checkpointing_enable()\n",
        "        base.config.use_cache = False\n",
        "    except Exception:\n",
        "        pass\n",
        "    base.to(DEVICE)\n",
        "\n",
        "    lora_cfg = LoraConfig(\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "        r=8, lora_alpha=16, lora_dropout=0.05,\n",
        "        target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
        "    )\n",
        "    model = get_peft_model(base, lora_cfg)\n",
        "\n",
        "    collator = DataCollatorForLanguageModeling(tokenizer=tok, mlm=False)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=OUTPUT_DIR,\n",
        "        seed=SEED,\n",
        "        num_train_epochs=EPOCHS,\n",
        "        per_device_train_batch_size=BATCH_SIZE,\n",
        "        gradient_accumulation_steps=GRAD_ACC,\n",
        "        learning_rate=LR,\n",
        "        logging_steps=5,\n",
        "        save_steps=1000,\n",
        "        report_to=\"none\",\n",
        "        dataloader_pin_memory=False,   # quiet on MPS\n",
        "        # keep args minimal for older transformers\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=tok_train,\n",
        "        eval_dataset=tok_eval,\n",
        "        data_collator=collator,\n",
        "        tokenizer=tok,\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== Training TECH LoRA adapter (tiny run) ===\")\n",
        "    trainer.train()\n",
        "\n",
        "    # save adapter\n",
        "    adapter_dir = os.path.join(OUTPUT_DIR, \"adapter\")\n",
        "    os.makedirs(adapter_dir, exist_ok=True)\n",
        "    trainer.model.save_pretrained(adapter_dir)\n",
        "    tok.save_pretrained(OUTPUT_DIR)\n",
        "\n",
        "    # tiny eval: loss → perplexity\n",
        "    try:\n",
        "        metrics = trainer.evaluate(tok_eval)\n",
        "        if \"eval_loss\" in metrics:\n",
        "            print(f\"Eval loss: {metrics['eval_loss']:.4f} | ppl≈{math.exp(float(metrics['eval_loss'])):.2f}\")\n",
        "    except Exception as e:\n",
        "        print(\"Eval skipped:\", repr(e))\n",
        "\n",
        "    print(f\"\\nSaved TECH LoRA adapter to: {adapter_dir}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "14cfb25cc4d145519a89fdb812afd4f1",
            "8703d8b614434a28b727949780818bbf",
            "4277c6ba2d8d456589ea0c5fc399822f",
            "79b7657130474e93ab6e891744c333ee",
            "01a664f04c9d48ef9e9935674f772425",
            "8504eac8129d467c922e23f3464e8134",
            "5c9c1e00c8564037bf37f55d635ea985",
            "a36f5f9541a84314ac8d67e18140d6d0",
            "2213a4967ca24263b9e62c4195726b84",
            "90262b04923b422ba84abab6519f4c4d",
            "ad471158c8624d58b22632ca88063a92",
            "58d52e3db62e480db79e9a6d2d2fe1f8",
            "b58f290691144106a90a6bbf01355635",
            "5a736e08d6fb409db9d2019bc8296643",
            "8a2e8a8f279b4a55b54f3e5e6bf2f7d8",
            "85c37a6505004f76937752e3dcfc8ee3",
            "ab3a4c7d6ca9458a98c248e83f2a463f",
            "3540e1c5d6de4d568b045af9c9cc163d",
            "8aaabc631e974e8794b4f71a26b61f80",
            "2b44f855002b4d8793dd00bb105ba485",
            "e2d46e7c876a49a18c4265bbcbace41b",
            "fe6ec56035ef464bb8844c0dcba29df5"
          ]
        },
        "id": "aZQjlUb71fs9",
        "outputId": "fcc25709-b20c-43ed-b019-010c5e74329f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14cfb25cc4d145519a89fdb812afd4f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58d52e3db62e480db79e9a6d2d2fe1f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2445284477.py:209: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training TECH LoRA adapter (tiny run) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2/2 00:02, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 : < :]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss: 1.4839 | ppl≈4.41\n",
            "\n",
            "Saved TECH LoRA adapter to: outputs/tinyllama-tech-lora/adapter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# infer_with_adapter_tech.py\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "MODEL_ID    = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "ADAPTER_DIR = \"outputs/tinyllama-tech-lora/adapter\"\n",
        "\n",
        "# device\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = \"cuda\"\n",
        "elif getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available():\n",
        "    DEVICE = \"mps\"\n",
        "else:\n",
        "    DEVICE = \"cpu\"\n",
        "\n",
        "def generate_with_adapter(endpoint_block: str, max_new_tokens=320):\n",
        "    tok = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "    if tok.pad_token is None:\n",
        "        tok.pad_token = tok.eos_token\n",
        "\n",
        "    base = AutoModelForCausalLM.from_pretrained(MODEL_ID).to(DEVICE).eval()\n",
        "    model = PeftModel.from_pretrained(base, ADAPTER_DIR).to(DEVICE).eval()\n",
        "\n",
        "    messages = build_messages(\n",
        "        \"tech\",\n",
        "        \"Write an API doc page. Follow the exact 4-section template.\",\n",
        "        endpoint_block\n",
        "    )\n",
        "    prompt = tok.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tok(prompt, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True, temperature=0.5, top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tok.eos_token_id,\n",
        "        )\n",
        "\n",
        "    # decode only new tokens beyond the prompt\n",
        "    gen_ids = out[0]\n",
        "    prompt_len = inputs[\"input_ids\"].shape[-1]\n",
        "    new_tokens = gen_ids[prompt_len:]\n",
        "    text = tok.decode(new_tokens, skip_special_tokens=True)\n",
        "\n",
        "    for m in [\"\\n[\", \"\\n<System\", \"\\nUser:\", \"\\nAssistant:\"]:\n",
        "        if m in text:\n",
        "            text = text.split(m, 1)[0]\n",
        "    return text.strip()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    endpoint = (\n",
        "        \"Endpoint: POST /v1/refunds; Auth: Bearer token; \"\n",
        "        \"Params: payment_id (string, required), amount (integer, optional); \"\n",
        "        \"Response: 201 {refund}, 400, 401\"\n",
        "    )\n",
        "    print(\"\\n=== AFTER FINE-TUNE (TECH LoRA adapter) ===\\n\")\n",
        "    print(generate_with_adapter(endpoint))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plo11nS65Pdx",
        "outputId": "ccaeaee7-8ff2-4d35-92d3-3685471a39bf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== AFTER FINE-TUNE (TECH LoRA adapter) ===\n",
            "\n",
            "[![API Doc Page](https://i.imgur.com/jY6ZTUA.png)](https://api.example.com/docs/v1/refunds)\n",
            "\n",
            "## Summary\n",
            "\n",
            "The `POST /v1/refunds` endpoint allows you to create a new refund for a specific payment.\n",
            "\n",
            "## Endpoint\n",
            "\n",
            "```\n",
            "POST /v1/refunds\n",
            "Authorization: Bearer [token]\n",
            "```\n",
            "\n",
            "## Parameters\n",
            "\n",
            "- `payment_id`: The unique identifier of the payment that will be refunded. This can be obtained from the `GET /payments/{id}` endpoint.\n",
            "- `amount`: The amount to be refunded in cents. Optional. If not provided, the default value is `1`.\n",
            "\n",
            "## Responses\n",
            "\n",
            "- `201`: Created response with the created refund object.\n",
            "- `400`: Bad request error if the `payment_id` parameter is invalid or missing.\n",
            "- `401`: Unauthorized error if the `Authorization` header is missing or incorrect.\n",
            "\n",
            "## Example Request\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"payment_id\": \"123\",\n",
            "    \"amount\": 500\n",
            "}\n",
            "```\n",
            "\n",
            "## Example Response\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"refund\": {\n",
            "        \"id\": \"abc123\",\n",
            "        \"created_at\": \"2021-0\n"
          ]
        }
      ]
    }
  ]
}